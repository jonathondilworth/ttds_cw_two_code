{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('../Tweets.14cat.train', 'r', 'cp1252') as file:\n",
    "    training_tweets = list(filter(str.strip, file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_link(input_string):\n",
    "    return re.sub(r\"http\\S+\", \"\", input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_spec_chars(input_string):\n",
    "    return re.sub(r\"[^\\w# @_]\", \"\", input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of tweets (string), no id, no label, links and special characters have been removed\n",
    "training_tweets_text = [remove_spec_chars(remove_link((tweet.split(\"\\t\"))[1].lower())) for tweet in training_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(word_tokenize(' '.join(training_tweets_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the set of features (BoW) will consist of integers (1->N) mapping each token (word) in the training set\n",
    "feature_set = dict(enumerate(list(unique_words), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write our feature set to file\n",
    "with codecs.open('./feats.dic', 'w', 'UTF-8') as file:\n",
    "    for attribute, value in feature_set.items():\n",
    "        file.write(\"{}\\t{}\\n\".format(attribute, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our application requires features to be attribute value pairs, where the attribute is the word & value is the int\n",
    "useable_feature_set = {v:k for k,v in feature_set.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_features = [tweet.split(\"\\t\") for tweet in training_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in training_tweets_features:\n",
    "    tweet[1] = remove_spec_chars(remove_link(tweet[1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup = {\n",
    "    'Autos & Vehicles':'1',\n",
    "    'Comedy':'2',\n",
    "    'Education':'3',\n",
    "    'Entertainment':'4',\n",
    "    'Film & Animation':'5',\n",
    "    'Gaming':'6',\n",
    "    'Howto & Style':'7',\n",
    "    'Music':'8',\n",
    "    'News & Politics':'9',\n",
    "    'Nonprofits & Activism':'10',\n",
    "    'Pets & Animals':'11',\n",
    "    'Science & Technology':'12',\n",
    "    'Sports':'13',\n",
    "    'Travel & Events':'14'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('./feats.train', 'w', 'UTF-8') as file:\n",
    "    for tweet in training_tweets_features:\n",
    "        try:\n",
    "            file.write(label_lookup[tweet[2].strip()] + \" \")\n",
    "            feature_body = []\n",
    "            for tweet_text in word_tokenize(tweet[1]):\n",
    "                try:\n",
    "                    feature_body.append(useable_feature_set[tweet_text.strip()])\n",
    "                except Exception:\n",
    "                    continue\n",
    "            feature_body = set(feature_body)\n",
    "            feature_body = sorted(feature_body)\n",
    "            file.write(' '.join([str(feature) + \":1\" for feature in feature_body]) + \" \")\n",
    "            file.write(\"#\" + str(tweet[0]) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"Whoops!\")\n",
    "            print(e)\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('../Tweets.14cat.test', 'r', 'cp1252') as file:\n",
    "    testing_tweets = list(filter(str.strip, file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_tweets_features = [tweet.split(\"\\t\") for tweet in testing_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in testing_tweets_features:\n",
    "    tweet[1] = remove_spec_chars(remove_link(tweet[1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./feats.test', 'w', 'UTF-8') as file:\n",
    "    for tweet in testing_tweets_features:\n",
    "        try:\n",
    "            file.write(label_lookup[tweet[2].strip()] + \" \")\n",
    "            feature_body = []\n",
    "            for tweet_text in word_tokenize(tweet[1]):\n",
    "                try:\n",
    "                    feature_body.append(useable_feature_set[tweet_text.strip()])\n",
    "                except Exception:\n",
    "                    continue\n",
    "            feature_body = set(feature_body)\n",
    "            feature_body = sorted(feature_body)\n",
    "            file.write(' '.join([str(feature) + \":1\" for feature in feature_body]) + \" \")\n",
    "            file.write(\"#\" + str(tweet[0]) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"Whoops!\")\n",
    "            print(e)\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
